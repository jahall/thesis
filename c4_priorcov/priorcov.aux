\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Prior Knowledge In Covariance Functions}{73}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Introduction}{73}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Problem Outline}{73}}
\newlabel{eqn:conttime}{{5.1}{73}}
\newlabel{eqn:cont-sample}{{5.6}{74}}
\newlabel{eqn:cD}{{5.7}{74}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Numerical Integration}{74}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Taylor-Series Expansion}{74}}
\newlabel{eqn:intdt}{{5.11}{74}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Settings of $a_{ip}$ and $b_i$ for some common Runge-Kutta methods.}}{75}}
\newlabel{tab:RKmeths}{{5.1}{75}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Runge-Kutta Methods}{75}}
\newlabel{eqn:RK1}{{5.12}{75}}
\newlabel{eqn:RK2}{{5.13}{75}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Prior over Sampled Continuous Time Systems}{76}}
\newlabel{sec:priorovercont}{{5.4}{76}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Illustrative Examples}{76}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}General Framework}{76}}
\newlabel{eqn:Mdelta}{{5.14}{76}}
\newlabel{eqn:Vdelta}{{5.15}{76}}
\newlabel{eqn:piter1}{{5.16}{77}}
\newlabel{eqn:piter2}{{5.17}{77}}
\newlabel{eqn:Efc}{{5.18}{77}}
\newlabel{eqn:Cfc}{{5.19}{77}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Non-Autonomous Case}{77}}
\newlabel{eqn:nonaut1}{{5.20}{77}}
\newlabel{eqn:nonaut2}{{5.21}{77}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Useful Kernels}{78}}
\newlabel{sec:usekernels}{{5.4.4}{78}}
\@writefile{toc}{\contentsline {subsubsection}{Class of Functions}{78}}
\@writefile{toc}{\contentsline {subsubsection}{Linear}{78}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Negative log-marginal likelihoods for discrete GPs with the continuous time prior $\mathcal  {GP}(\mathbf  {0},\mathbf  {K}_{\text  {full}})$ trained on data from the \textit  {unconstrained} pendulum. The graph is obtained from 50 Monte-Carlo runs for different values of $\delta _t$. The bars depict the 50$\ensuremath  {^{\text  {th}}}$ percentile while the whiskers show the 25$\ensuremath  {^{\text  {th}}}$ to 75$\ensuremath  {^{\text  {th}}}$ percentile.}}{79}}
\newlabel{fig:pend_SEonly}{{5.1}{79}}
\@writefile{toc}{\contentsline {subsubsection}{Squared Exponential Kernel}{79}}
\newlabel{eqn:SEprop}{{5.29}{79}}
\@writefile{toc}{\contentsline {subsubsection}{Additive Squared Exponential Kernel}{79}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces The average of the learned hyperparameters for methods trained using a $\mathcal  {GP}(\mathbf  {0},\mathbf  {K}_{\text  {full}})$ continuous time prior and a setting of $\delta _t=0.4\tmspace  +\thinmuskip {.1667em}$s on the \textit  {unconstrained} pendulum data. The numbers in bold depict important changes from the Euler to the RK4 method.}}{80}}
\newlabel{tab:hyps_SEdt04}{{5.2}{80}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.5}Example: Pendulum}{80}}
\newlabel{sec:pendulum2}{{5.4.5}{80}}
\@writefile{toc}{\contentsline {subsubsection}{Inferring Linear Plus Nonlinear Structure}{80}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Average negative log-marginal likelihoods for discrete GPs with the continuous time prior $\mathcal  {GP}(\mathbf  {m}_{\text  {lin}},\mathbf  {K}_{\text  {full}})$ trained on data from the \textit  {unconstrained} pendulum. The graph is obtained from 50 Monte-Carlo runs for different values of $\delta _t$. The bars depict the 50$\ensuremath  {^{\text  {th}}}$ percentile while the whiskers show the 25$\ensuremath  {^{\text  {th}}}$ to 75$\ensuremath  {^{\text  {th}}}$ percentile.}}{81}}
\newlabel{fig:pend_SEandLIN}{{5.2}{81}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces The average of the learned hyperparameters for methods trained using a $\mathcal  {GP}(\mathbf  {m}_{\text  {lin}},\mathbf  {K}_{\text  {full}})$ continuous time prior and a setting of $\delta _t=0.4\tmspace  +\thinmuskip {.1667em}$s on the \textit  {unconstrained} pendulum data. The numbers in bold depict important changes from the Euler to the RK4 method.}}{82}}
\newlabel{tab:hyps_dt04}{{5.3}{82}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces The average of the learned hyperparameters for methods trained using a $\mathcal  {GP}(\mathbf  {m}_{\text  {lin}},\mathbf  {K}_{\text  {full}})$ continuous time prior and a setting of $\delta _t=0.1\tmspace  +\thinmuskip {.1667em}$s on the \textit  {unconstrained} pendulum data. The numbers in bold depict important changes from the Euler to the RK4 method.}}{82}}
\newlabel{tab:hyps_dt01}{{5.4}{82}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Comparison of the predictive performance of the RK-based methods given a continuous-time prior $\mathcal  {GP}(\mathbf  {m}_{\text  {lin}},\mathbf  {K}_{\text  {full}})$ using the RMS and nLPD metrics and based on data from the \textit  {unconstrained} pendulum. The graph is obtained from 50 Monte-Carlo runs for different values of $\delta _t$. The bars depict the 50$\ensuremath  {^{\text  {th}}}$ percentile while the whiskers show the 25$\ensuremath  {^{\text  {th}}}$ to 75$\ensuremath  {^{\text  {th}}}$ percentile.}}{83}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Root mean square errors}}}{83}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Negative log-predictive density errors}}}{83}}
\newlabel{fig:pend_validate}{{5.3}{83}}
\@writefile{toc}{\contentsline {subsubsection}{Inferring Linear Plus Additive Structure}{83}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Negative log-marginal likelihoods for discrete GPs with the continuous time prior $\mathcal  {GP}(\mathbf  {m}_{\text  {lin}},\mathbf  {K}_{\text  {add}} + \mathbf  {K}_{\text  {full}})$ trained on data from the \textit  {artificially constrained} pendulum. The graph is obtained from 50 Monte-Carlo runs for different values of $\delta _t$. The bars depict the 50$\ensuremath  {^{\text  {th}}}$ percentile while the whiskers show the 25$\ensuremath  {^{\text  {th}}}$ to 75$\ensuremath  {^{\text  {th}}}$ percentile.}}{84}}
\newlabel{fig:pend2_SEaSEandLIN}{{5.4}{84}}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces The average of the learned hyperparameters for methods trained using a $\mathcal  {GP}(\mathbf  {m}_{\text  {lin}},\mathbf  {K}_{\text  {add}}+\mathbf  {K}_{\text  {full}})$ continuous time prior and a setting of $\delta _t=0.4\tmspace  +\thinmuskip {.1667em}$s on the \textit  {artificially constrained} pendulum data. The numbers in bold depict important changes from the Euler to the RK4 method.}}{84}}
\newlabel{tab:hyps2_dt04}{{5.5}{84}}
\citation{SMLL03}
\citation{Sar11}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Comparison of the predictive performance of the RK-based methods given a continuous-time prior $\mathcal  {GP}(\mathbf  {m}_{\text  {lin}},\mathbf  {K}_{\text  {add}} + \mathbf  {K}_{\text  {full}})$ using the RMS and nLPD metrics and based on data from the \textit  {unconstrained} pendulum. The graph is obtained from 50 Monte-Carlo runs for different values of $\delta _t$. The bars depict the 50$\ensuremath  {^{\text  {th}}}$ percentile while the whiskers show the 25$\ensuremath  {^{\text  {th}}}$ to 75$\ensuremath  {^{\text  {th}}}$ percentile.}}{85}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Root mean square errors}}}{85}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Negative log-predictive density errors}}}{85}}
\newlabel{fig:pend2_validate}{{5.5}{85}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Combining Continuous and Sampled Data}{85}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Single Data Points}{85}}
\newlabel{eqn:cDD}{{5.35}{85}}
\newlabel{eqn:lalalala}{{5.36}{85}}
\citation{AK11}
\citation{AK08}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Derivative Observations}{86}}
\@writefile{toc}{\contentsline {subsubsection}{Overview}{86}}
\@writefile{toc}{\contentsline {subsubsection}{General Kernels}{86}}
\@writefile{toc}{\contentsline {subsubsection}{Squared Exponential Kernel}{86}}
\@writefile{toc}{\contentsline {subsubsection}{Squared Exponential Kernel}{87}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}Local Model Validation}{87}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Summary}{88}}
\@setckpt{c4_priorcov/priorcov}{
\setcounter{page}{89}
\setcounter{equation}{40}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{6}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{5}
\setcounter{table}{5}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{parentequation}{0}
\setcounter{proof}{6}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{NAT@ctr}{0}
\setcounter{r@tfl@t}{0}
\setcounter{blindtext}{1}
\setcounter{Blindtext}{5}
\setcounter{blindlist}{0}
\setcounter{blindlistlevel}{0}
\setcounter{blindlist@level}{0}
\setcounter{blind@listcount}{0}
\setcounter{blind@levelcount}{0}
\setcounter{lips@count}{0}
\setcounter{defin}{0}
\setcounter{ass}{0}
\setcounter{theo}{0}
\setcounter{algo}{0}
\setcounter{lem}{0}
}
